{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "aed1f1e4-8d87-47e0-8b29-a35abb25ffec",
   "metadata": {},
   "outputs": [],
   "source": [
    "from astropy.coordinates import SkyCoord\n",
    "from astropy.coordinates.name_resolve import NameResolveError\n",
    "from astropy.table import Table, Row, vstack, unique, hstack\n",
    "from astropy.time import Time\n",
    "from astropy import units as u\n",
    "\n",
    "from astroquery.vizier import Vizier\n",
    "\n",
    "from IPython.display import clear_output\n",
    "\n",
    "import numpy\n",
    "\n",
    "from pathlib import Path\n",
    "\n",
    "import pickle"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "daf55d63-c5ba-4711-b16b-d675621dccbf",
   "metadata": {},
   "outputs": [],
   "source": [
    "DATA_PATH = Path(\"//stem-linux-homes/OSL-Telescope/data/users/Pipeline/PIRATE/\")\n",
    "NUM_CALIBRATION_ROWS = 10\n",
    "CALIBRATION_CATALOGUE = 'I/284/out'\n",
    "CALIBRATION_CATALOGUE_FIELDS = {\n",
    "    'B': 'B1mag',\n",
    "    'R': 'R1mag',\n",
    "    'I': 'Imag',\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "8241d12c-3c83-433d-b26c-4a04e885eac0",
   "metadata": {},
   "outputs": [],
   "source": [
    "try: \n",
    "    with open('data/processed_dates.pickle', 'rb') as processed_dates_file:\n",
    "        processed_dates = pickle.load(processed_dates_file)\n",
    "except FileNotFoundError:\n",
    "    processed_dates = []"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "7680671b-28fa-4910-b471-a5f4f85bfbb4",
   "metadata": {},
   "outputs": [],
   "source": [
    "try: \n",
    "    with open('data/coords.pickle', 'rb') as coords_file:\n",
    "        coords = pickle.load(coords_file)\n",
    "except FileNotFoundError:\n",
    "    coords = {}"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "eb22e006-6105-41ab-bd0b-a9c2f113bb42",
   "metadata": {},
   "source": [
    "To do:\n",
    "- Take account of flags (maybe don't do this at this step and leave it for later)\n",
    "- Calibration"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "28ababc2-2d96-4505-99ef-fbbcaad05afe",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[655/659] Processing PIRATE_419624_OSL_00_anm83_HD38451_00_B15_00_2021_10_21_04_34_56_OR_CB_PS\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING: MergeConflictWarning: Cannot merge meta key 'null' types <class 'float'> and <class 'float'>, choosing null=nan [astropy.utils.metadata]\n"
     ]
    }
   ],
   "source": [
    "new_dates = [p for p in DATA_PATH.glob('202?_??_??') if p not in processed_dates]\n",
    "total_dates = len(new_dates)\n",
    "obs_tables = {}\n",
    "\n",
    "SPLIT_SIZE = 10\n",
    "\n",
    "for date_i, date in enumerate(new_dates):\n",
    "    for catalogue in date.glob('Catalogues/*_anm83_*.cat'):\n",
    "        obs_meta = catalogue.stem.split('_')\n",
    "        obs_meta = {\n",
    "            'name': obs_meta[5],\n",
    "            'band': obs_meta[7][0],\n",
    "            'exposure': obs_meta[7][1:],\n",
    "            'timestamp': Time(\n",
    "                dict(zip(\n",
    "                    ['year', 'month', 'day', 'hour', 'minute', 'second'],\n",
    "                    map(int, obs_meta[9:15])\n",
    "                )),\n",
    "                format='ymdhms',\n",
    "            ).jd,\n",
    "        }\n",
    "        if obs_meta['name'] not in coords:\n",
    "            try:\n",
    "                coords[obs_meta['name']] = SkyCoord.from_name(obs_meta['name'], parse=True)\n",
    "            except NameResolveError:\n",
    "                continue\n",
    "        if obs_meta['band'] == 'V':\n",
    "            # To do: How to handle the lack of V mags in USNO?\n",
    "            continue\n",
    "        clear_output(wait=True)\n",
    "        print(f'[{date_i}/{total_dates}] Processing {catalogue.stem}')\n",
    "        \n",
    "        table = Table.read(catalogue, format='ascii.sextractor')\n",
    "        table.rename_column('ALPHA_J2000', 'RA')\n",
    "        table.rename_column('DELTA_J2000', 'Dec')\n",
    "        \n",
    "        table['separation'] = SkyCoord.guess_from_table(table).separation(coords[obs_meta['name']])\n",
    "        table.sort('separation') #To do: use idxmin here instead of sorting\n",
    "        target_row = table[0]\n",
    "        \n",
    "        # Do USNO vizier query for contents of table, then take the closest few matching rows\n",
    "        # to use for calibration\n",
    "        \n",
    "        table.rename_column('RA', '_RAJ2000')\n",
    "        table.rename_column('Dec', '_DEJ2000')\n",
    "        Path(f\"data/calibration_tables/{obs_meta['name']}\").mkdir(parents=True, exist_ok=True)\n",
    "        try:\n",
    "            calibration_table = Table.read(f\"data/calibration_tables/{obs_meta['name']}/{catalogue.stem}.ecsv\")\n",
    "        except FileNotFoundError:\n",
    "            table['flux_diff'] = numpy.abs(table['FLUX_AUTO'] - target_row['FLUX_AUTO'])\n",
    "            table.sort('flux_diff')\n",
    "\n",
    "            calibration_rows = []\n",
    "\n",
    "            total_iterations = int(len(table) / SPLIT_SIZE) + 1\n",
    "            for i in range(total_iterations):\n",
    "                sources = table[table['FLAGS'] == 0][i * SPLIT_SIZE : (i+1) * SPLIT_SIZE]\n",
    "                if len(sources) == 0:\n",
    "                    continue\n",
    "                sources = vstack([ row for row in sources if row['NUMBER'] != target_row['NUMBER'] ])\n",
    "                catalogue_results = Vizier.query_region(sources, radius=1e-4*u.deg, catalog=CALIBRATION_CATALOGUE)\n",
    "                if len(catalogue_results) == 0:\n",
    "                    continue\n",
    "\n",
    "                # Reject any sources with multiple matches\n",
    "                catalogue_matches = unique(catalogue_results[0], '_q', keep='none')\n",
    "\n",
    "                # To do: Reject any known variables\n",
    "\n",
    "                for catalogue_row in catalogue_matches:\n",
    "                    calibration_rows.append(hstack([\n",
    "                        sources[int(catalogue_row['_q']) - 1],\n",
    "                        catalogue_row[[CALIBRATION_CATALOGUE_FIELDS[obs_meta['band']]]],\n",
    "                    ]))\n",
    "\n",
    "                if len(calibration_rows) >= NUM_CALIBRATION_ROWS:\n",
    "                    break\n",
    "            if len(calibration_rows) < NUM_CALIBRATION_ROWS:\n",
    "                continue\n",
    "            calibration_table = vstack(calibration_rows[:NUM_CALIBRATION_ROWS])\n",
    "            calibration_table.write(f\"data/calibration_tables/{obs_meta['name']}/{catalogue.stem}.ecsv\")\n",
    "        \n",
    "        calibrated_mags = calibration_table[CALIBRATION_CATALOGUE_FIELDS[obs_meta['band']]] - 2.5 * numpy.log10(target_row['FLUX_AUTO'] / calibration_table['FLUX_AUTO'])\n",
    "        \n",
    "        out_table = Table(target_row)\n",
    "        # To do: Maybe this should be a weighted average using the flux error?\n",
    "        out_table.add_columns(\n",
    "            [\n",
    "                numpy.mean(calibrated_mags),\n",
    "                numpy.std(calibrated_mags),\n",
    "            ],\n",
    "            names=['calibrated_mag', 'calibrated_mag_err'],\n",
    "        )\n",
    "        \n",
    "        for key, val in obs_meta.items():\n",
    "            out_table[key] = val\n",
    "        \n",
    "        if obs_meta['name'] not in obs_tables:\n",
    "            try:\n",
    "                obs_tables[obs_meta['name']] = Table.read(f\"data/{obs_meta['name']}.ecsv\")\n",
    "            except FileNotFoundError:\n",
    "                obs_tables[obs_meta['name']] = out_table\n",
    "                continue\n",
    "        obs_tables[obs_meta['name']] = vstack([obs_tables[obs_meta['name']], out_table])\n",
    "        \n",
    "    processed_dates.append(date)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "03cc5012-89c8-4a60-99cd-38db9312a047",
   "metadata": {},
   "outputs": [],
   "source": [
    "for name, table in obs_tables.items():\n",
    "    table.write(f\"data/{name}.ecsv\", overwrite=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "27e2fe8f-c6c6-454d-ac97-460fc5c9fdb7",
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('data/processed_dates.pickle', 'wb') as processed_dates_file:\n",
    "    pickle.dump(processed_dates, processed_dates_file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "704b847a-dbc3-4fc2-8ce4-ecf1fe1c6dab",
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('data/coords.pickle', 'wb') as coords_file:\n",
    "    pickle.dump(coords, coords_file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bfa27474-870e-463a-a140-7c9d777bb090",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
