{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "aed1f1e4-8d87-47e0-8b29-a35abb25ffec",
   "metadata": {},
   "outputs": [],
   "source": [
    "from astropy.coordinates import SkyCoord\n",
    "from astropy.coordinates.name_resolve import NameResolveError\n",
    "from astropy.table import Table, Row, vstack, unique, hstack\n",
    "from astropy.time import Time\n",
    "from astropy import units as u\n",
    "\n",
    "from astroquery.vizier import Vizier\n",
    "\n",
    "from IPython.display import clear_output\n",
    "\n",
    "import numpy\n",
    "\n",
    "from pathlib import Path\n",
    "\n",
    "import pickle"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "daf55d63-c5ba-4711-b16b-d675621dccbf",
   "metadata": {},
   "outputs": [],
   "source": [
    "DATA_PATH = Path(\"//stem-linux-homes/OSL-Telescope/data/users/Pipeline/\")\n",
    "NUM_CALIBRATION_ROWS = 10\n",
    "CALIBRATION_CATALOGUE = 'I/284/out'\n",
    "CALIBRATION_CATALOGUE_FIELDS = {\n",
    "    'B': 'B1mag',\n",
    "    'R': 'R1mag',\n",
    "    'I': 'Imag',\n",
    "}\n",
    "REPROCESS = False # Set to True to reprocess previous data rather than finding new data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "8241d12c-3c83-433d-b26c-4a04e885eac0",
   "metadata": {},
   "outputs": [],
   "source": [
    "try: \n",
    "    with open('data/processed_dates.pickle', 'rb') as processed_dates_file:\n",
    "        processed_dates = pickle.load(processed_dates_file)\n",
    "except FileNotFoundError:\n",
    "    processed_dates = {}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "7680671b-28fa-4910-b471-a5f4f85bfbb4",
   "metadata": {},
   "outputs": [],
   "source": [
    "try: \n",
    "    with open('data/coords.pickle', 'rb') as coords_file:\n",
    "        coords = pickle.load(coords_file)\n",
    "except FileNotFoundError:\n",
    "    coords = {}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "179a6a9d-13e7-4add-aea8-c9d21e59df21",
   "metadata": {},
   "outputs": [],
   "source": [
    "if REPROCESS:\n",
    "    processed_dates = [ d for d, has_data in processed_dates.items() if not has_data ]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "28ababc2-2d96-4505-99ef-fbbcaad05afe",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0/1] Processing PIRATE_421144_OSL_00_anm83_HD38451_00_V10_00_2021_10_27_04_10_26_OR_CB_PS\n"
     ]
    }
   ],
   "source": [
    "new_dates = [p for p in DATA_PATH.glob('*/202?_??_??') if p not in processed_dates]\n",
    "total_dates = len(new_dates)\n",
    "obs_tables = {}\n",
    "\n",
    "SPLIT_SIZE = 10\n",
    "\n",
    "for date_i, date in enumerate(new_dates):\n",
    "    date_has_data = False\n",
    "    for catalogue in date.glob('Catalogues/*_anm83_*.cat'):\n",
    "        date_has_data = True\n",
    "        obs_meta = catalogue.stem.split('_')\n",
    "        obs_meta = {\n",
    "            'telescope': obs_meta[0],\n",
    "            'name': obs_meta[5],\n",
    "            'band': obs_meta[7][0],\n",
    "            'exposure': float(obs_meta[7][1:]),\n",
    "            'timestamp': Time(\n",
    "                dict(zip(\n",
    "                    ['year', 'month', 'day', 'hour', 'minute', 'second'],\n",
    "                    map(int, obs_meta[9:15])\n",
    "                )),\n",
    "                format='ymdhms',\n",
    "            ).jd,\n",
    "        }\n",
    "        if obs_meta['name'] not in coords:\n",
    "            try:\n",
    "                coords[obs_meta['name']] = SkyCoord.from_name(obs_meta['name'], parse=True)\n",
    "            except NameResolveError:\n",
    "                continue\n",
    "        clear_output(wait=True)\n",
    "        print(f'[{date_i}/{total_dates}] Processing {catalogue.stem}')\n",
    "        \n",
    "        table = Table.read(catalogue, format='ascii.sextractor')\n",
    "        table.rename_column('ALPHA_J2000', 'RA')\n",
    "        table.rename_column('DELTA_J2000', 'Dec')\n",
    "        \n",
    "        table['separation'] = SkyCoord.guess_from_table(table).separation(coords[obs_meta['name']])\n",
    "        table.sort('separation') #To do: use idxmin here instead of sorting\n",
    "        target_row = table[0]\n",
    "        out_table = Table(target_row)\n",
    "        \n",
    "        # Do USNO vizier query for contents of table, then take the closest few matching rows\n",
    "        # to use for calibration\n",
    "        \n",
    "        table.rename_column('RA', '_RAJ2000')\n",
    "        table.rename_column('Dec', '_DEJ2000')\n",
    "        Path(f\"data/calibration_tables/{obs_meta['name']}\").mkdir(parents=True, exist_ok=True)\n",
    "        if obs_meta['band'] in CALIBRATION_CATALOGUE_FIELDS:\n",
    "            try:\n",
    "                calibration_table = Table.read(f\"data/calibration_tables/{obs_meta['name']}/{catalogue.stem}.ecsv\")\n",
    "            except FileNotFoundError:\n",
    "                table['flux_diff'] = numpy.abs(table['FLUX_AUTO'] - target_row['FLUX_AUTO'])\n",
    "                table.sort('flux_diff')\n",
    "\n",
    "                calibration_rows = []\n",
    "\n",
    "                total_iterations = int(len(table) / SPLIT_SIZE) + 1\n",
    "                for i in range(total_iterations):\n",
    "                    sources = table[table['FLAGS'] == 0][i * SPLIT_SIZE : (i+1) * SPLIT_SIZE]\n",
    "                    if len(sources) == 0:\n",
    "                        continue\n",
    "                    sources = vstack([ row for row in sources if row['NUMBER'] != target_row['NUMBER'] ])\n",
    "                    catalogue_results = Vizier.query_region(sources, radius=1e-4*u.deg, catalog=CALIBRATION_CATALOGUE)\n",
    "                    if len(catalogue_results) == 0:\n",
    "                        continue\n",
    "\n",
    "                    # Reject any sources with multiple matches\n",
    "                    catalogue_matches = unique(catalogue_results[0], '_q', keep='none')\n",
    "\n",
    "                    # To do: Reject any known variables\n",
    "\n",
    "                    for catalogue_row in catalogue_matches:\n",
    "                        calibration_rows.append(hstack([\n",
    "                            sources[int(catalogue_row['_q']) - 1],\n",
    "                            catalogue_row[[CALIBRATION_CATALOGUE_FIELDS[obs_meta['band']]]],\n",
    "                        ]))\n",
    "\n",
    "                    if len(calibration_rows) >= NUM_CALIBRATION_ROWS:\n",
    "                        break\n",
    "                if len(calibration_rows) < NUM_CALIBRATION_ROWS:\n",
    "                    continue\n",
    "                calibration_table = vstack(calibration_rows[:NUM_CALIBRATION_ROWS])\n",
    "                calibration_table.write(f\"data/calibration_tables/{obs_meta['name']}/{catalogue.stem}.ecsv\")\n",
    "\n",
    "            calibrated_mags = (\n",
    "                calibration_table[CALIBRATION_CATALOGUE_FIELDS[obs_meta['band']]] \n",
    "                - 2.5 * numpy.log10(target_row['FLUX_AUTO'] / calibration_table['FLUX_AUTO'])\n",
    "            )\n",
    "\n",
    "            # To do: Maybe this should be a weighted average using the flux error?\n",
    "            out_table.add_columns(\n",
    "                [\n",
    "                    numpy.mean(calibrated_mags),\n",
    "                    numpy.std(calibrated_mags),\n",
    "                ],\n",
    "                names=['calibrated_mag', 'calibrated_mag_err'],\n",
    "            )\n",
    "        else:\n",
    "            # To do: How to handle the lack of V mags in USNO?\n",
    "            out_table.add_columns(\n",
    "                [\n",
    "                    numpy.nan,\n",
    "                    numpy.nan,\n",
    "                ],\n",
    "                names=['calibrated_mag', 'calibrated_mag_err'],\n",
    "            )\n",
    "        \n",
    "        for key, val in obs_meta.items():\n",
    "            out_table[key] = val\n",
    "        \n",
    "        if obs_meta['name'] not in obs_tables:\n",
    "            try:\n",
    "                if REPROCESS:\n",
    "                    obs_tables[obs_meta['name']] = out_table\n",
    "                    continue\n",
    "                else:\n",
    "                    obs_tables[obs_meta['name']] = Table.read(f\"data/{obs_meta['name']}.ecsv\")\n",
    "            except FileNotFoundError:\n",
    "                obs_tables[obs_meta['name']] = out_table\n",
    "                continue\n",
    "        obs_tables[obs_meta['name']] = vstack([obs_tables[obs_meta['name']], out_table])\n",
    "        \n",
    "    if not REPROCESS:\n",
    "        processed_dates[date] = date_has_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "03cc5012-89c8-4a60-99cd-38db9312a047",
   "metadata": {},
   "outputs": [],
   "source": [
    "for name, table in obs_tables.items():\n",
    "    table.write(f\"data/{name}.ecsv\", overwrite=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "27e2fe8f-c6c6-454d-ac97-460fc5c9fdb7",
   "metadata": {},
   "outputs": [],
   "source": [
    "if not REPROCESS:\n",
    "    with open('data/processed_dates.pickle', 'wb') as processed_dates_file:\n",
    "        pickle.dump(processed_dates, processed_dates_file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "704b847a-dbc3-4fc2-8ce4-ecf1fe1c6dab",
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('data/coords.pickle', 'wb') as coords_file:\n",
    "    pickle.dump(coords, coords_file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bfa27474-870e-463a-a140-7c9d777bb090",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
